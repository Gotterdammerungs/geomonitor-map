import os
import time
import json
import re
import requests
from datetime import datetime, timedelta

# ============================================================
# üåç GEOLOCATOR IMPORTS (safe Geoapify fallback)
# ============================================================
try:
    from geopy.geocoders import Nominatim, Geoapify
    GEOAPIFY_AVAILABLE = True
except ImportError:
    from geopy.geocoders import Nominatim
    Geoapify = None
    GEOAPIFY_AVAILABLE = False
from geopy.exc import GeocoderTimedOut, GeocoderServiceError

# ============================================================
# üß≠ LOGGING
# ============================================================
def log(msg: str):
    print(f"[{datetime.utcnow().strftime('%H:%M:%S')}] {msg}")

# ============================================================
# ‚öôÔ∏è CONFIG
# ============================================================
FIREBASE_URL = os.environ.get(
    "FIREBASE_URL",
    "https://geomonitor-2025-default-rtdb.europe-west1.firebasedatabase.app/"
)
NEWS_API_KEY = os.environ.get("NEWS_API_KEY")
GEOAPIFY_KEY = os.environ.get("GEOAPIFY_KEY")
OPENROUTER_KEY = os.environ.get("OPENROUTER_API_KEY")
AI_IS_ON = True  # toggle manually

log("Booting Geomonitor Data Injector...")
log(f"Firebase URL: {FIREBASE_URL}")
log(f"NewsAPI key: {'‚úÖ Present' if NEWS_API_KEY else '‚ùå Missing'}")
log(f"Geoapify key: {'‚úÖ Present' if GEOAPIFY_KEY else '‚ö†Ô∏è Missing'}")
log(f"OpenRouter key: {'‚úÖ Present' if OPENROUTER_KEY else '‚ö†Ô∏è Missing'}")

if not NEWS_API_KEY:
    log("‚ùå Missing NEWS_API_KEY; cannot continue.")
    exit(1)

# ============================================================
# üìò LOAD DICTIONARY
# ============================================================
DICTIONARY_PATH = os.path.join(os.path.dirname(__file__), "dictionary.json")
try:
    with open(DICTIONARY_PATH, "r", encoding="utf-8") as f:
        CUSTOM_LOCATIONS = json.load(f)
    log(f"üìò Loaded {len(CUSTOM_LOCATIONS)} dictionary entries.")
except Exception as e:
    log(f"‚ö†Ô∏è Could not load dictionary file: {e}")
    CUSTOM_LOCATIONS = {}

# ============================================================
# üî§ REGEX
# ============================================================
PLACE_REGEX = re.compile(r"\b(?:in|at|near|from)\s+([A-Z][a-zA-Z]+(?:\s+[A-Z][a-zA-Z]+)*)")
DATELINE_REGEX = re.compile(r"^\s*([A-Z][A-Z]+|[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)(?:\s*‚Äî|,)")

# ============================================================
# üß† AI FALLBACK (Mistral 7B via OpenRouter)
# ============================================================
def ai_guess_location(article):
    if not AI_IS_ON or not OPENROUTER_KEY:
        return None

    title = article.get("title", "")
    desc = article.get("description", "")
    text = f"Title: {title}\nDescription: {desc}\n\nReturn only one likely city or country. You are forbidden to say anything alse. you must prioritise the city in which it happens, if you dont know, then return the province, or state, and if you cannot, then return the nation."

    try:
        resp = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENROUTER_KEY}",
                "Content-Type": "application/json",
            },
            json={
                "model": "mistralai/mistral-7b-instruct",
                "messages": [
                    {"role": "system", "content": "You extract geographic locations, you are only allowed to answer a location, you will not, under any circumstance, say anything more, than the guessed location name.you must prioritise the city in which it happens, if you dont know, then return the province, or state, and if you cannot, then return the nation."},
                    {"role": "user", "content": text},
                ],
                "max_tokens": 15,
                "temperature": 0.2,
            },
            timeout=20,
        )
        guess = resp.json()["choices"][0]["message"]["content"].strip()
        log(f"üß† AI guessed location ‚Üí {guess}")
        return guess
    except Exception as e:
        log(f"‚ö†Ô∏è AI inference failed: {e}")
        return None

# ============================================================
# üìç LOCATION HELPERS
# ============================================================
def extract_dateline_location(text: str):
    if not text:
        return None
    match = DATELINE_REGEX.match(text)
    if match:
        raw = match.group(1).strip()
        return CUSTOM_LOCATIONS.get(raw.lower(), raw)
    return None

def extract_location_hint(text: str):
    if not text:
        return None
    match = PLACE_REGEX.search(text)
    if match:
        raw_place = match.group(1).strip()
        return CUSTOM_LOCATIONS.get(raw_place.lower(), raw_place)
    return None

# ============================================================
# üåç GEOLOCATORS
# ============================================================
try:
    geolocator_nom = Nominatim(user_agent="geomonitor_news_app")
    geolocator_geo = Geoapify(api_key=GEOAPIFY_KEY) if GEOAPIFY_AVAILABLE and GEOAPIFY_KEY else None
    if geolocator_geo:
        log("‚úÖ Initialized geocoders: Nominatim + Geoapify fallback.")
    else:
        log("‚úÖ Initialized Nominatim geocoder (Geoapify unavailable).")
except Exception as e:
    log(f"‚ùå Geocoder init failed: {e}")
    exit(1)

def geocode_location(location_name: str):
    if not location_name:
        return None, None
    clean_name = (
        location_name.strip()
        .replace(" - ", ", ")
        .replace("USA", "")
        .replace("Inc.", "")
        .replace("Headquarters", "")
        .strip(", ")
    )
    log(f"Attempting geocode for hint: '{clean_name}'")
    time.sleep(1.2)
    try:
        loc = geolocator_nom.geocode(clean_name, timeout=10)
        if loc:
            log(f"üó∫Ô∏è Nominatim ‚Üí '{clean_name}' ‚Üí ({loc.latitude:.4f}, {loc.longitude:.4f})")
            return loc.latitude, loc.longitude
    except Exception as e:
        log(f"‚ö†Ô∏è Nominatim error: {e}")

    if geolocator_geo:
        try:
            loc = geolocator_geo.geocode(clean_name, timeout=10)
            if loc:
                log(f"üåê Geoapify ‚Üí '{clean_name}' ‚Üí ({loc.latitude:.4f}, {loc.longitude:.4f})")
                return loc.latitude, loc.longitude
        except Exception as e:
            log(f"‚ö†Ô∏è Geoapify error: {e}")

    return None, None

# ============================================================
# üîé LOCATION RESOLUTION PIPELINE
# ============================================================
def resolve_location_name(article: dict):
    src = (article.get("source", {}) or {}).get("name", "")
    title = article.get("title", "") or ""
    desc = article.get("description", "") or ""
    combined = f"{title} {desc}"

    key = src.lower().strip()
    if key in CUSTOM_LOCATIONS:
        log(f"üìï Dictionary source match: {key} ‚Üí {CUSTOM_LOCATIONS[key]}")
        return CUSTOM_LOCATIONS[key]

    dateline = extract_dateline_location(combined)
    if dateline:
        log(f"üì∞ Dateline match ‚Üí {dateline}")
        return dateline

    lower_text = combined.lower()
    for word, loc in sorted(CUSTOM_LOCATIONS.items(), key=lambda kv: -len(kv[0])):
        if len(word) <= 2:
            continue
        if re.search(rf"\b{re.escape(word.lower())}\b", lower_text):
            log(f"üìó Keyword match ‚Üí {word} ‚Üí {loc}")
            return loc

    regex_hint = extract_location_hint(combined)
    if regex_hint:
        log(f"üìç Regex match ‚Üí {regex_hint}")
        return regex_hint

    if AI_IS_ON:
        guess = ai_guess_location(article)
        if guess:
            log(f"üß© Using AI location guess: {guess}")
            return guess

    log("‚ö†Ô∏è No location found by any method.")
    return None

# ============================================================
# üì∞ FETCH NEWS (with relevance filter)
# ============================================================
def fetch_and_geocode_news():
    TOPICS = [
        "geopolitics",
        "international relations",
        "war OR conflict",
        "finance OR stock market OR economic crisis",
        "technology OR AI OR semiconductor OR cyber attack",
        "natural disaster OR earthquake OR hurricane"
    ]
    QUERY = " OR ".join(TOPICS)
    url = f"https://newsapi.org/v2/everything?q={QUERY}&language=en&sortBy=publishedAt&pageSize=30&apiKey={NEWS_API_KEY}"
    log(f"Fetching news: {url}")

    try:
        data = requests.get(url, timeout=20).json()
        articles = data.get("articles", [])
        log(f"Fetched {len(articles)} raw articles.")
    except Exception as e:
        log(f"‚ùå Failed to fetch: {e}")
        return {}

    # -------- Filtering irrelevant fluff --------
    REJECT_KEYWORDS = [
        "recipe", "bake", "fashion", "celebrity", "film", "tv", "movie",
        "video game", "football", "nba", "halloween", "netflix", "prime video",
        "music", "album", "concert", "review", "sports", "holiday", "pets",
        "horoscope", "dating", "lifestyle", "garden", "cooking", "travel"
    ]
    filtered = []
    for art in articles:
        title = (art.get("title") or "").lower()
        desc = (art.get("description") or "").lower()
        if any(bad in title or bad in desc for bad in REJECT_KEYWORDS):
            continue
        filtered.append(art)
    articles = filtered
    log(f"Filtered down to {len(articles)} relevant articles.")

    # -------- Process and geocode --------
    events = {}
    for i, art in enumerate(articles):
        title = art.get("title", "Untitled").strip()
        log(f"\n[{i+1}/{len(articles)}] Processing: {title}")

        loc_hint = resolve_location_name(art)
        if not loc_hint:
            log("‚ùå No location hint found; skipping.")
            continue

        lat, lon = geocode_location(loc_hint)
        if lat and lon:
            key = f"news_{int(time.time())}_{i}"
            events[key] = {
                "title": title,
                "description": art.get("description", "No Description"),
                "type": (art.get("source", {}) or {}).get("name", "General News"),
                "severity": "Info",
                "url": art.get("url", "#"),
                "lat": lat,
                "lon": lon,
                "timestamp": art.get("publishedAt") or datetime.utcnow().isoformat(),
            }
    return events

# ============================================================
# üî• PUSH TO FIREBASE
# ============================================================
def push_batch_events(new_events):
    fb_url = f"{FIREBASE_URL}/events.json"
    cutoff = datetime.utcnow() - timedelta(days=2)
    try:
        old = requests.get(fb_url, timeout=10).json() or {}
        log(f"Fetched {len(old)} existing events.")
    except Exception:
        old = {}
    kept = {}
    for key, ev in old.items():
        ts = ev.get("timestamp")
        if not ts:
            continue
        try:
            if datetime.fromisoformat(ts.replace("Z", "")) > cutoff:
                kept[key] = ev
        except Exception:
            continue
    log(f"Keeping {len(kept)} old events (last 2 days).")
    merged = {**kept, **new_events}
    try:
        r = requests.put(fb_url, data=json.dumps(merged))
        r.raise_for_status()
        log(f"‚úÖ PUSH COMPLETE: {len(merged)} total events.")
    except Exception as e:
        log(f"‚ùå PUSH FAILED: {e}")

# ============================================================
# üöÄ MAIN
# ============================================================
if __name__ == "__main__":
    log("=== Starting Data Injection Job ===")
    events = fetch_and_geocode_news()
    push_batch_events(events)
    log("=== Job Complete ===")
