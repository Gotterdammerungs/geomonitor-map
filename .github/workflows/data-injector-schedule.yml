import time
import os
import requests
import json
import re
from datetime import datetime, timedelta

# ============================================================
# üåç GEOLOCATOR IMPORTS (safe Geoapify fallback)
# ============================================================
try:
    from geopy.geocoders import Nominatim, Geoapify
    GEOAPIFY_AVAILABLE = True
except ImportError:
    from geopy.geocoders import Nominatim
    Geoapify = None
    GEOAPIFY_AVAILABLE = False

from geopy.exc import GeocoderTimedOut, GeocoderServiceError

# ============================================================
# üß≠ LOGGING HELPER
# ============================================================
def log(msg):
    print(f"[{datetime.utcnow().strftime('%H:%M:%S')}] {msg}")

# ============================================================
# ‚öôÔ∏è CONFIGURATION
# ============================================================
FIREBASE_URL = os.environ.get("FIREBASE_URL", "https://geomonitor-2025-default-rtdb.europe-west1.firebasedatabase.app")
NEWS_API_KEY = os.environ.get("NEWS_API_KEY")
GEOAPIFY_KEY = os.environ.get("GEOAPIFY_KEY")

log("Booting Geomonitor Data Injector...")
log(f"Firebase URL: {FIREBASE_URL or '‚ùå NOT SET'}")
log(f"NewsAPI key: {'‚úÖ Present' if NEWS_API_KEY else '‚ùå NOT SET'}")
log(f"Geoapify key: {'‚úÖ Present' if GEOAPIFY_KEY else '‚ö†Ô∏è Missing (fallback disabled)'}")

if not FIREBASE_URL or not NEWS_API_KEY:
    log("FATAL ERROR: FIREBASE_URL or NEWS_API_KEY environment variable is not set.")
    exit(1)

# ============================================================
# üìò LOAD EXTERNAL DICTIONARY
# ============================================================
DICTIONARY_PATH = os.path.join(os.path.dirname(__file__), "dictionary.json")
try:
    with open(DICTIONARY_PATH, "r", encoding="utf-8") as f:
        CUSTOM_LOCATIONS = json.load(f)
    log(f"üìò Loaded {len(CUSTOM_LOCATIONS)} entries from dictionary.json")
except Exception as e:
    log(f"‚ö†Ô∏è Could not load dictionary file: {e}")
    CUSTOM_LOCATIONS = {}

# ============================================================
# üß† REGEX PATTERNS
# ============================================================
PLACE_REGEX = re.compile(r"\b(?:in|at|near|from)\s+([A-Z][a-zA-Z]+(?:\s+[A-Z][a-zA-Z]+)*)")
DATELINE_REGEX = re.compile(r"^\s*([A-Z][A-Z]+|[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)(?:\s*‚Äî|,)", re.UNICODE)

# ============================================================
# üß© LOCATION RESOLUTION
# ============================================================
def extract_dateline_location(text):
    """Detects leading dateline like 'OTTAWA ‚Äî' or 'London,'."""
    if not text:
        return None
    match = DATELINE_REGEX.match(text)
    if match:
        raw = match.group(1).strip()
        normalized = CUSTOM_LOCATIONS.get(raw.lower(), raw)
        return normalized
    return None


def extract_location_hint(text):
    """Finds phrases like 'in Paris' or 'from New York City'."""
    if not text:
        return None
    match = PLACE_REGEX.search(text)
    if match:
        raw_place = match.group(1).strip()
        normalized = CUSTOM_LOCATIONS.get(raw_place.lower(), raw_place)
        return normalized
    return None


def resolve_location_name(article):
    """
    Priority:
      1Ô∏è‚É£ Dictionary (source name)
      2Ô∏è‚É£ Dateline detection
      3Ô∏è‚É£ Keyword in text
      4Ô∏è‚É£ Regex fallback
    """
    src = (article.get("source", {}) or {}).get("name", "")
    title = article.get("title", "") or ""
    desc = article.get("description", "") or ""
    combined = f"{title} {desc}"

    # 1Ô∏è‚É£ Dictionary
    key = src.lower().strip()
    if key in CUSTOM_LOCATIONS:
        log(f"üìï Dictionary source match: {key} ‚Üí {CUSTOM_LOCATIONS[key]}")
        return CUSTOM_LOCATIONS[key]

    # 2Ô∏è‚É£ Dateline
    dateline = extract_dateline_location(title + " " + desc)
    if dateline:
        log(f"üì∞ Dateline match ‚Üí {dateline}")
        return dateline

    # 3Ô∏è‚É£ Keyword
    lower_text = combined.lower()
    for word, loc in CUSTOM_LOCATIONS.items():
        if word in lower_text:
            log(f"üìó Keyword match: {word} ‚Üí {loc}")
            return loc

    # 4Ô∏è‚É£ Regex
    regex_hint = extract_location_hint(combined)
    if regex_hint:
        log(f"üìç Regex match ‚Üí {regex_hint}")
        return regex_hint

    log("‚ö†Ô∏è No location found by any method.")
    return None

# ============================================================
# üåç GEOLOCATION (Nominatim + Geoapify Fallback)
# ============================================================
try:
    geolocator_nom = Nominatim(user_agent="geomonitor_news_app")
    geolocator_geo = Geoapify(api_key=GEOAPIFY_KEY) if GEOAPIFY_AVAILABLE and GEOAPIFY_KEY else None
    if geolocator_geo:
        log("‚úÖ Initialized geocoders: Nominatim + Geoapify fallback.")
    else:
        log("‚úÖ Initialized Nominatim geocoder (Geoapify unavailable).")
except Exception as e:
    log(f"‚ùå Geocoder initialization error: {e}")
    exit(1)


def geocode_location(location_name):
    if not location_name:
        return None, None

    location_name = location_name.strip().replace(" - ", ", ")
    time.sleep(1.2)  # respect rate limit
    try:
        loc = geolocator_nom.geocode(f"{location_name}, global", timeout=10)
        if loc:
            log(f"üó∫Ô∏è Nominatim ‚Üí '{location_name}' ‚Üí ({loc.latitude:.4f}, {loc.longitude:.4f})")
            return loc.latitude, loc.longitude
    except Exception as e:
        log(f"‚ö†Ô∏è Nominatim failed for '{location_name}': {e}")

    # Geoapify fallback
    if geolocator_geo:
        try:
            loc = geolocator_geo.geocode(location_name, timeout=10)
            if loc:
                log(f"üåê Geoapify ‚Üí '{location_name}' ‚Üí ({loc.latitude:.4f}, {loc.longitude:.4f})")
                return loc.latitude, loc.longitude
            else:
                log(f"‚ö†Ô∏è Geoapify could not find '{location_name}'")
        except Exception as e:
            log(f"‚ö†Ô∏è Geoapify error for '{location_name}': {e}")

    return None, None

# ============================================================
# üì∞ FETCH NEWS
# ============================================================
def fetch_and_geocode_news():
    url = (
        f"https://newsapi.org/v2/everything?q=world&language=en&"
        f"sortBy=publishedAt&pageSize=15&apiKey={NEWS_API_KEY}"
    )
    log(f"Fetching news from NewsAPI: {url}")

    try:
        data = requests.get(url, timeout=15).json()
        articles = data.get("articles", [])
        log(f"Fetched {len(articles)} articles.")
    except Exception as e:
        log(f"‚ùå Failed to fetch NewsAPI: {e}")
        return {}

    events = {}
    for i, art in enumerate(articles):
        title = art.get("title", "").strip() or "Untitled"
        log(f"\n[{i+1}/{len(articles)}] Processing: {title}")

        loc_hint = resolve_location_name(art)
        if not loc_hint:
            log("‚ùå No location hint found; skipping.")
            continue

        lat, lon = geocode_location(loc_hint)
        if lat and lon:
            key = f"news_{int(time.time())}_{i}"
            events[key] = {
                "title": title,
                "description": art.get("description", "No Description"),
                "type": (art.get("source", {}) or {}).get("name", "General News"),
                "severity": "Info",
                "url": art.get("url", "#"),
                "lat": lat,
                "lon": lon,
                "timestamp": art.get("publishedAt") or datetime.utcnow().isoformat(),
            }
    return events

# ============================================================
# üî• MERGE + CLEANUP EVENTS
# ============================================================
def push_batch_events(new_events):
    fb_url = f"{FIREBASE_URL}/events.json"
    cutoff = datetime.utcnow() - timedelta(days=2)

    # Fetch existing
    try:
        old = requests.get(fb_url, timeout=10).json() or {}
        log(f"Fetched {len(old)} existing events from Firebase.")
    except Exception as e:
        log(f"‚ö†Ô∏è Could not fetch existing data: {e}")
        old = {}

    # Keep only recent
    kept = {}
    for key, ev in old.items():
        try:
            ts = ev.get("timestamp")
            ts_dt = datetime.fromisoformat(ts.replace("Z", "")) if isinstance(ts, str) else datetime.utcfromtimestamp(float(ts))
            if ts_dt > cutoff:
                kept[key] = ev
        except Exception:
            pass
    log(f"Keeping {len(kept)} old events (newer than 2 days).")

    # Merge and push
    merged = {**kept, **new_events}
    try:
        log(f"Pushing {len(merged)} merged events ‚Üí {fb_url}")
        r = requests.put(fb_url, data=json.dumps(merged))
        r.raise_for_status()
        log(f"‚úÖ PUSH COMPLETE: {len(merged)} total events now stored.")
    except Exception as e:
        log(f"‚ùå PUSH FAILED: {e}")

# ============================================================
# üöÄ MAIN EXECUTION
# ============================================================
if __name__ == "__main__":
    log("=== Starting Data Injection Job ===")
    events = fetch_and_geocode_news()
    push_batch_events(events)
    log("=== Job Complete ===")
